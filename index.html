<!DOCTYPE html>
<html>
    <head>
        <title>codemastery</title>
        <link rel="icon" type="image/x-icon" href="/media/favicon.ico">
        <link rel="stylesheet" href="style.css">
        <script src="scripts.js"></script>
    </head>
    <body>
        <div class="header">
            <img id="logo" src="media/logo.png">
            <h1 id="header-title">codemastery</h1>
        </div>
        <div class="tabs-header">
            <div class="tab active" data-tab="ml-engineer" onclick="selectTab('ml-engineer')">
                <h1 class="tab-title">Machine Learning/AI Engineer</h1>
                <a href="https://www.codecademy.com/learn/paths/machine-learning-engineer" target="_blank"><h3 class="tab-platform">codecademy</h3></a>
            </div>
            <div class="tab" data-tab="data-scientist" onclick="selectTab('data-scientist')">
                <h1 class="tab-title">Data Scientist: Machine Learning Specialist</h1>
                <a href="https://www.codecademy.com/learn/paths/data-science" target="_blank"><h3 class="tab-platform">codecademy</h3></a>
            </div>
        </div>
        <div class="content">
            <div class="tab-content active" data-content="ml-engineer">
                <h1>Machine Learning/AI Engineer</h1>
                <div class="progress-bar">
                    <div class="progress-bar-fulfilled-ml-engineer">12%</div>
                </div>
                <div class="table-of-contents">
                    <h2 id="table-of-contents-title">Table of Contents</h2>
                    <a href="#supervised-unsupervised-learning" id="table-of-contents-link">Supervised vs Unsupervised Learning</a>
                    <a href="#feature-engineering-data-transformation" id="table-of-contents-link">Feature Engineering & Data Transformation</a>
                    <a href="#supervised-learning-i" id="table-of-contents-link">Supervised Learning I</a>
                </div>
                <div class="chapter">
                    <h2 id="supervised-unsupervised-learning" onclick="displayChapter('supervised-unsupervised-learning-chapter')">▼ Supervised vs Unsupervised Learning:</h2>
                    <div class="chapter-content open" id="supervised-unsupervised-learning-chapter">
                        <ul>
                            <li><b>Supervised Learning</b>: data is labeled and the program learns to predict the output from the input data.</li>
                            <li><b>Unsupervised Learning</b>: data is unlabeled and the program learns to recognize the inherent structure or pattern in the input data.</li>
                        </ul>
                    </div>
                </div>
                <div class="chapter">
                    <h2 id="feature-engineering-data-transformation" onclick="displayChapter('feature-engineering-data-transformation-chapter')">▼ Feature Engineering & Data Transformation:</h2>
                    <div class="chapter-content open" id="feature-engineering-data-transformation-chapter">
                        <p>Features are measurable properties in a dataset, i.e. predictor variables.</p>
                        <ul>
                            <li><b>Feature Transformation</b>: refers to transforming numerical data and to encoding non-numerical variables. Some of these methods are: scaling, binning, logarithming transformations, hashing, and one hot encoding. It is usually used in order to improve performance, runtime and interpretability.</li>
                            <li><b>Dimensionality Reduction</b>: refers to the reduction of the number of features within a dataset, therefore improving runtime, and often performance.</li>
                            <li><b>Feature Selection</b>: refers to the different techniques used for choosing the features. Most of these techniques belong to one of these categories:
                                <ol>
                                    <li><b>Filer methods</b>: Statistical techniques used to filter out useful features. These are <i>model agnostic</i>, meaning they can be used with any ML models. They include: correlation coefficients (Pearson, Spearman, etc.), chi^2, ANOVA, and Mutual Information calculations.</li>
                                    <li><b>Wrapper methods</b>: These methods use a <i>greedy search strategy</i> to pick the best set of features. They do this by picking a subset of features, training a model, evaluating it, and trying a different subset over and over again till a stopping criterion (either based on the number of features, or a model performance metric) is achieved. Some of these methods are: Forward Feature Selection, Backward Feature Elimination and Sequential Floating.</li>
                                    <li><b>Embedded methods</b>: These methods are implemented <i>during the model implementation step</i>. Regularization techniques such as Lasso or Ridge tweak the model to get it to generalize better to new and unknown data.</li>
                                </ol>
                            </li>
                        </ul>

                        <p><b>Natural Log Transformation</b> is used to allow the data to be closer to a <i>normal</i> distribution, as well as to decrease the range between the minimum and the maximum values of the dataset. This can help the model perform better. This kind of tranformation can only be applied if you have non-negative, parametric, and right-skewed data.</p>

                        <pre class="code-block">
                            <code>
                            <span class="keyword">import</span> <span class="variable">numpy</span> <span class="keyword">as</span> <span class="variable">np</span>
                            <br><br>
                            <span class="variable">data</span>
                            <br><br>
                            <span class="variable">log_data</span> = <span class="variable">np</span>.<span class="function">log</span>(<span class="variable">data</span>)
                            </code>
                        </pre>  
                        
                        <p><b>Encoding Categorical Data</b> can be of two types:</p>
                        <ol>
                            <li>Nominal data, or data that has no order or hierarchy to it.</li>
                            <li>Ordinal data, or data that have order, but the differences between the categories are either not important or unclear.</li>
                        </ol>

                        <p>The type of such data is usually an <i>object</i>, so it is either text or a mixture between text and numerical values.</p>

                        <pre class="code-block">
                            <code>
                            <span class="variable">data</span>
                            <br><br>
                            <span class="function">print</span>(<span class="variable">data</span>.<span class="function">dtypes</span>)
                            <br><br>
                            <span class="comment">#OUTPUT</span>
                            <br><br>
                            <span class="comment">#data    object</span>
                            </code>
                        </pre>

                        <p><b>Transforming categorical data</b> into numerical values can be done in multiple ways, some of which are:</p>
                        <ul>
                            <li>
                                <p><b>Ordinal encoding</b></p>
                                <p>This can only be applied to ordinal data, and it implies assigning a numerical value to each category.</p>
                                <p>Example: the ratings of a product on an E-Commerce Platform.</p>
                                <p>First way we can take: manually assign the values through a dictionary, just like this:</p>
                                <pre class="code-block">
                                    <code>
                                    <span class="variable">rating_dict</span> = { <span class="value">'Excellent'</span>:<span class="variable">5</span>, <span class="value">'New'</span>:<span class="variable">4</span>, <span class="value">'Like new'</span>:<span class="variable">3</span>, <span class="value">'Good'</span>:<span class="variable">2</span>, <span class="value">'Fair'</span>:<span class="variable">1</span>}
                                    <br><br>
                                    <span class="variable">data</span> = <span class="variable">data</span>.<span class="function">map</span>(<span class="variable">rating_dict</span>)
                                    </code>
                                </pre>
                                <p>The second approach we can take is to use sklearn.preprocessing's OrdinalEncoder library, as such:</p>
                                <pre class="code-block">
                                    <code>
                                    <span class="keyword">from</span> <span class="variable">sklearn</span>.<span class="function">preprocessing</span> <span class="keyword">import</span> <span class="variable">OrdinalEncoder</span>
                                    <br><br>
                                    <span class="variable">encoder</span> = <span class="variable">OrdinalEncoder</span>(<span class="variable">categories</span>=[[<span class="value">'Excellent'</span>, <span class="value">'New'</span>, <span class="value">'Like New'</span>, <span class="value">'Good'</span>, <span class="value">'Fair'</span>]])
                                    <br><br>
                                    <span class="variable">data_reshaped</span> = <span class="variable">data</span>.<span class="function">values</span>.<span class="function">reshape</span>(<span class="variable">-1</span>, <span class="variable">1</span>)
                                    <br><br>
                                    <span class="variable">data_transformed</span> = <span class="variable">data</span>.<span class="function">fit_transform</span>(<span class="variable">data_reshaped</span>)
                                    </code>
                                </pre>
                            </li>
                            <li>
                                <p><b>Label Encoding</b></p>
                                <p>Label Encoding is used for nominal data, and the idea behind this technique is to assign a number (or code) to each category. This can raise some problems, as the model can interpret a characteristic as more important, or give it more weight, as it's number/code is greater than another. This can be, however, resolved by using <i>One-hot Encoding</i>.</p>
                                <p>Example: the colors of a group of cars.</p>
                                <p>First approach we can take is to convert the feature from an <i>object</i> type to a <i>categories</i> one, like this:</p>
                                <pre class="code-block">
                                    <code>
                                    <span class="variable">cars</span>[<span class="value">'color'</span>] = <span class="variable">cars</span>[<span class="value">'color'</span>].<span class="function">astype</span>(<span class="value">'category'</span>)
                                    <br><br>
                                    <span class="variable">cars</span>[<span class="value">'color'</span>] = <span class="variable">cars</span>[<span class="value">'color'</span>].<span class="function">cat</span>.<span class="function">codes</span>
                                    <br><br>
                                    <span class="keyword">print</span>(<span class="variable">cars</span>[<span class="value">'color'</span>].<span class="function">value_counts</span>()[:<span class="variable">5</span>])<br>
                                    <span class="comment">#OUTPUT</span><br>
                                    <span class="comment"># 2     2015<br># 18    1931<br># 8     1506<br># 15    1503<br># 3      869</span>
                                    </code>
                                </pre>
                                <p>The second one is using the LabelEncoder library of sklearn.preprocessing, as below:</p>
                                <pre class="code-block">
                                    <code>
                                    <span class="keyword">from</span> <span class="variable">sklearn</span>.<span class="function">preprocessing</span> <span class="keyword">import</span> <span class="variable">LabelEncoder</span>
                                    <br><br>
                                    <span class="variable">encoder</span> = <span class="variable">LabelEncoder</span>()
                                    <br><br>
                                    <span class="variable">cars</span>[<span class="value">'color'</span>] = <span class="variable">encoder</span>.<span class="function">fit_transform</span>(<span class="variable">cars</span>[<span class="value">'color'</span>])
                                    </code>
                                </pre>
                            </li>
                            <li>
                                <p><b>One-hot Encoding</b></p>
                                <p>This is used in order to solve the problem that arises with Label Encoding, and it does that by creating <i>dummy variables</i> that take either 1 or 0 numerical values for each category. The issue with this approach is that it can easily create a huge amount of features.</p>
                                <pre class="code-block">
                                    <code>
                                    <span class="keyword">import</span> <span class="variable">pandas</span> <span class="keyword">as</span> <span class="variable">pd</span>
                                    <br><br>
                                    <span class="variable">ohe</span> = <span class="variable">pd</span>.<span class="function">get_dummies</span>(<span class="variable">cars</span>[<span class="value">'color'</span>])
                                    <br><br>
                                    <span class="variable">cars</span> = <span class="variable">cars</span>.<span class="function">join</span>(<span class="variable">ohe</span>)
                                    </code>
                                </pre>
                            </li>
                            <li>
                                <p><b>Binary Encoding</b></p>
                                <p>Similar to One-hot Encoding, Binary Encoding comes to solve the issues other techniques have, however, this time it's about One-hot Encoding. In order to minimize the amount of features, it creates the representation in binary of each category.</p>
                                <p>For example, if we have 19 colors, instead of creating 19 features, it assigns to each color a number (blue = 1, green = 2, red = 3, etc.) and then it represents these numbers in binary (1 = 1, 2 = 10, 3 = 11, ..., 19 = 10011). As there are 5 digits for 19 numbers, we can use only 5 features, each taking either a 1 or a 0.</p>
                                <pre class="code-block">
                                    <code>
                                    <span class="keyword">from</span> <span class="variable">category_encoders</span> <span class="keyword">import</span> <span class="variable">BinaryEncoder</span>
                                    <br><br>
                                    <span class="variable">colors</span> = <span class="variable">BinaryEncoder</span>(<span class="variable">cols</span> = [<span class="value">'color'</span>], <span class="variable">drop_invariant</span> = <span class="keyword">True</span>).<span class="function">fit_transform</span>(<span class="variable">cars</span>)
                                    </code>
                                </pre>
                            </li>
                            <li>
                                <p><b>Hashing</b></p>
                                <p>Similar to One-hot Encoding, Hashing creates new features, however it allows us to input the number of features we want to create, which can reduce dimensionality. However this comes with a new problem, that of mapping categories to the same values, an issue called <i>collision</i>.</p>
                                <p>Having 19 colors, if we create through Hashing only 5 new features, we will definitely have some colors with the same hash values, so the model will not be able to differentiate between them.</p>
                                <pre class="code-block">
                                    <code>
                                    <span class="keyword">from</span> <span class="variable">category_encoders</span> <span class="keyword">import</span> <span class="variable">HashingEncoder</span>
                                    <br><br>
                                    <span class="variable">encoder</span> = <span class="variable">HashingEncoder</span>(<span class="variable">cols</span>=<span class="value">'color'</span>, <span class="variable">n_components</span>=<span class="variable">5</span>)
                                    <br><br>
                                    <span class="variable">hash_results</span> = <span class="variable">encoder</span>.<span class="function">fit_transform</span>(<span class="variable">cars</span>[<span class="value">'color'</span>])
                                    </code>
                                </pre>
                            </li>
                            <li>
                                <p><b>Target Encoding</b></p>
                                <p>Target Encoding, also called Mean Encoding, refers to the technique of calculating the mean of a specific numerical feature based on the entities that have the same non-numerical value, in proportion to the overall mean.</p>
                                <p>For example, for the colors, we can find the mean of the car's prices per color combined with the mean of all the cars prices.</p>
                                <pre class="code-block">
                                    <code>
                                    <span class="keyword">from</span> <span class="variable">category_encoders</span> <span class="keyword">import</span> <span class="variable">TargetEncoder</span>
                                    <br><br>
                                    <span class="variable">encoder</span> = <span class="variable">TargetEncoder</span>(<span class="variable">cols</span>=<span class="value">'color'</span>)
                                    <br><br>
                                    <span class="variable">encoder_results</span> = <span class="variable">encoder</span>.<span class="function">fit_transform</span>(<span class="variable">cars</span>[<span class="value">'color'</span>], <span class="variable">cars</span>[<span class="value">'sellingprice'</span>])
                                    </code>
                                </pre>
                            </li>
                            <li>
                                <p><b>Date-time Encoding</b></p>
                                <p>This one is used to convert date-time objects to numerical ones. Some ways to o this is to extract only the year, month, day, etc out of the date-time.</p>
                                <pre class="code-block">
                                    <code>
                                        <span class="comment">#Assuming df['datetime'] is a date-time object:</span>
                                        <br><br>
                                        <span class="variable">df</span>[<span class="value">'datetime</span>].<span class="function">dt</span>.<span class="function">year</span><br>
                                        <span class="variable">df</span>[<span class="value">'datetime</span>].<span class="function">dt</span>.<span class="function">month</span><br>
                                        <span class="variable">df</span>[<span class="value">'datetime</span>].<span class="function">dt</span>.<span class="function">day</span><br>
                                        <span class="variable">df</span>[<span class="value">'datetime</span>].<span class="function">dt</span>.<span class="function">hour</span><br>
                                        <span class="variable">df</span>[<span class="value">'datetime</span>].<span class="function">dt</span>.<span class="function">minute</span><br>
                                        <span class="variable">df</span>[<span class="value">'datetime</span>].<span class="function">dt</span>.<span class="function">second</span><br>
                                        <span class="variable">df</span>[<span class="value">'datetime</span>].<span class="function">dt</span>.<span class="function">week</span> <span class="comment">#The week ordinal of the year.</span><br>
                                        <span class="variable">df</span>[<span class="value">'datetime</span>].<span class="function">dt</span>.<span class="function">dayofweek</span> <span class="comment">#The day of the week (Monday = 0 & Sunday = 6).</span>
                                    </code>
                                </pre>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="chapter">
                    <h2 id="supervised-learning-i" onclick="displayChapter('supervised-learning-i-chapter')">▼ Supervised Learning I:</h2>
                    <div class="chapter-content open" id="supervised-learning-i-chapter">
                        <p><b>Regression vs Classification</b>:</p>
                        <ul>
                            <li><p><b>Regression</b>: is used to predict outputs that are continous, such as the height a plant will have based on the amount of rainfall.</p></li>
                            <li><p><b>Classification</b>: is used to predict a discrete label, having a finite set of possible outcomes. Most have only two possible outcomes (i.e. whether it will rain or not), but it can have multiple labels as well (i.e. what species of animal is present in an image).</p></li>
                        </ul>

                        <p><b>Linear Regression</b>: tries to find the best line (<i>slope</i> and <i>intercept</i>, or position) that matches as closely as possible the data points derived from two variables, therefore being able to utilize that line to predict the value of one variable starting from a new, unknown value of the other.</p>
                        <br>
                        <p>The formula of a linear function:</p>
                        <p id="math">y=mx+b</p>
                        <p>where m is the slope and b is the intercept.</p>
                        <br>
                        <p>The <i>loss</i> (or error) of the model can be calculated as the sum of the loss (squared distance) of all the available points.</p>
                        <p id="math">Σ(lᵢ)</p>
                        <p>where:</p>
                        <p id="math">lᵢ = (distance to the line)²</p>
                        <br>
                        <p>The goal of a linear regression model is to find the slope and intercept pair that minimizes loss on average across all of the data.</p>
                        <p>In order to find the best pair, we use a <i>gradient descent</i> for each element of the pair. Here are the mathematical formulas for both:</p>
                        <ul>
                            <li>
                                <p>Gradient Descent for Intercept:</p>
                                <p id="math">−
                                    <math>
                                    <mfrac>
                                      <mn>2</mn>
                                      <mi>N</mi>
                                    </mfrac>
                                  </math>
                                Σ(yᵢ-(mxᵢ+b))</p>
                                <p>where N is the number of points in our dataset, m is the current gradient guess and b is the current intercept guess.</p>
                            </li>
                            <li>
                                <p>Gradient Descent for Slope:</p>
                                <p id="math">−
                                    <math>
                                    <mfrac>
                                      <mn>2</mn>
                                      <mi>N</mi>
                                    </mfrac>
                                  </math>
                                Σxᵢ(yᵢ-(mxᵢ+b))</p>
                            </li>
                        </ul>

                        <p>To take a step on a gradient slope, we can use the following formula:</p>
                        <pre class="code-block">
                            <code>
                                <span class="variable">new_value</span> = <span class="variable">current_value</span> - (<span class="variable">learning_rate</span> * <span class="variable">gradient</span>)
                            </code>
                        </pre>
                        <p>where current_variable is the guess we have for either the <i>slope</i>, or the <i>intercept</i>, and the learning_rate is a variable we set proportional to the size of the step we want to take. This step should not be too small, nor too big, so that we do not have to take too many steps, or even worse, to overshoot the minimum loss. </p>

                        <p>Convergence refers to the moment loss stops changing or changes very slowly.</p>

                        <pre class="code-block">
                            <code>
                            <span class="keyword">import</span> <span class="variable">matplotlib.pyplot</span> <span class="keyword">as</span> <span class="variable">plt</span>
                            <br><br>
                            <span class="keyword">def</span> <span class="function">get_gradient_at_b</span>(<span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">b</span>, <span class="variable">m</span>):
                              <br>&nbsp;&nbsp;<span class="variable">N</span> = <span class="function">len</span>(<span class="variable">x</span>)
                              <br>&nbsp;&nbsp;<span class="variable">diff</span> = <span class="value">0</span>
                              <br>&nbsp;&nbsp;<span class="keyword">for</span> <span class="variable">i</span> <span class="keyword">in</span> <span class="function">range</span>(<span class="variable">N</span>):
                              <br>&nbsp;&nbsp;&nbsp;&nbsp;<span class="variable">x_val</span> = <span class="variable">x</span>[<span class="variable">i</span>]
                              <br>&nbsp;&nbsp;&nbsp;&nbsp;<span class="variable">y_val</span> = <span class="variable">y</span>[<span class="variable">i</span>]
                              <br>&nbsp;&nbsp;&nbsp;&nbsp;<span class="variable">diff</span> += (<span class="variable">y_val</span> - ((<span class="variable">m</span> * <span class="variable">x_val</span>) + <span class="variable">b</span>))
                              <br>&nbsp;&nbsp;<span class="variable">b_gradient</span> = -(<span class="value">2</span>/<span class="variable">N</span>) * <span class="variable">diff</span>  
                              <br>&nbsp;&nbsp;<span class="keyword">return</span> <span class="variable">b_gradient</span>
                              <br><br>
                        
                            <span class="keyword">def</span> <span class="function">get_gradient_at_m</span>(<span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">b</span>, <span class="variable">m</span>):
                              <br>&nbsp;&nbsp;<span class="variable">N</span> = <span class="function">len</span>(<span class="variable">x</span>)
                              <br>&nbsp;&nbsp;<span class="variable">diff</span> = <span class="value">0</span>
                              <br>&nbsp;&nbsp;<span class="keyword">for</span> <span class="variable">i</span> <span class="keyword">in</span> <span class="function">range</span>(<span class="variable">N</span>):
                              <br>&nbsp;&nbsp;&nbsp;&nbsp;<span class="variable">x_val</span> = <span class="variable">x</span>[<span class="variable">i</span>]
                              <br>&nbsp;&nbsp;&nbsp;&nbsp;<span class="variable">y_val</span> = <span class="variable">y</span>[<span class="variable">i</span>]
                              <br>&nbsp;&nbsp;&nbsp;&nbsp;<span class="variable">diff</span> += <span class="variable">x_val</span> * (<span class="variable">y_val</span> - ((<span class="variable">m</span> * <span class="variable">x_val</span>) + <span class="variable">b</span>))
                              <br>&nbsp;&nbsp;<span class="variable">m_gradient</span> = -(<span class="value">2</span>/<span class="variable">N</span>) * <span class="variable">diff</span>  
                              <br>&nbsp;&nbsp;<span class="keyword">return</span> <span class="variable">m_gradient</span>
                              <br><br>
                        
                            <span class="keyword">def</span> <span class="function">step_gradient</span>(<span class="variable">b_current</span>, <span class="variable">m_current</span>, <span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">learning_rate</span>):
                              <br>&nbsp;&nbsp;<span class="variable">b_gradient</span> = <span class="function">get_gradient_at_b</span>(<span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">b_current</span>, <span class="variable">m_current</span>)
                              <br>&nbsp;&nbsp;<span class="variable">m_gradient</span> = <span class="function">get_gradient_at_m</span>(<span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">b_current</span>, <span class="variable">m_current</span>)
                              <br>&nbsp;&nbsp;<span class="variable">b</span> = <span class="variable">b_current</span> - (<span class="variable">learning_rate</span> * <span class="variable">b_gradient</span>)
                              <br>&nbsp;&nbsp;<span class="variable">m</span> = <span class="variable">m_current</span> - (<span class="variable">learning_rate</span> * <span class="variable">m_gradient</span>)
                              <br>&nbsp;&nbsp;<span class="keyword">return</span> [<span class="variable">b</span>, <span class="variable">m</span>]
                              <br><br>
                        
                            <span class="keyword">def</span> <span class="function">gradient_descent</span>(<span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">learning_rate</span>, <span class="variable">num_iterations</span>):
                              <br>&nbsp;&nbsp;<span class="variable">b</span> = <span class="value">0</span>
                              <br>&nbsp;&nbsp;<span class="variable">m</span> = <span class="value">0</span>
                              <br>&nbsp;&nbsp;<span class="keyword">for</span> <span class="variable">i</span> <span class="keyword">in</span> <span class="function">range</span>(<span class="variable">num_iterations</span>):
                              <br>&nbsp;&nbsp;&nbsp;&nbsp;[<span class="variable">b</span>, <span class="variable">m</span>] = <span class="function">step_gradient</span>(<span class="variable">b</span>, <span class="variable">m</span>, <span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">learning_rate</span>)
                              <br>&nbsp;&nbsp;<span class="keyword">return</span> <span class="variable">b</span>, <span class="variable">m</span>
                              <br><br>
                        
                            <span class="variable">months</span> = [<span class="value">1</span>, <span class="value">2</span>, <span class="value">3</span>, <span class="value">4</span>, <span class="value">5</span>, <span class="value">6</span>, <span class="value">7</span>, <span class="value">8</span>, <span class="value">9</span>, <span class="value">10</span>, <span class="value">11</span>, <span class="value">12</span>]
                            <br><span class="variable">revenue</span> = [<span class="value">52</span>, <span class="value">74</span>, <span class="value">79</span>, <span class="value">95</span>, <span class="value">115</span>, <span class="value">110</span>, <span class="value">129</span>, <span class="value">126</span>, <span class="value">147</span>, <span class="value">146</span>, <span class="value">156</span>, <span class="value">184</span>]
                            <br><br>
                        
                            <span class="variable">b</span>, <span class="variable">m</span> = <span class="function">gradient_descent</span>(<span class="variable">months</span>, <span class="variable">revenue</span>, <span class="value">0.01</span>, <span class="value">1000</span>)
                            <br><span class="variable">y</span> = [<span class="variable">m</span>*<span class="variable">x</span> + <span class="variable">b</span> <span class="keyword">for</span> <span class="variable">x</span> <span class="keyword">in</span> <span class="variable">months</span>]
                            <br><br>
                        
                            <span class="variable">plt</span>.<span class="function">plot</span>(<span class="variable">months</span>, <span class="variable">revenue</span>, <span class="value">"o"</span>)
                            <br><span class="variable">plt</span>.<span class="function">plot</span>(<span class="variable">months</span>, <span class="variable">y</span>)
                            <br><span class="variable">plt</span>.<span class="function">show</span>()
                            </code>
                        </pre>
                        
                        <p>We can also use sklearn.linear_model's LinearRegression, as such:</p>

                        <pre class="code-block">
                            <code>
                            <span class="keyword">from</span> <span class="variable">sklearn.linear_model</span> <span class="keyword">import</span> <span class="variable">LinearRegression</span>
                            <br><span class="keyword">import</span> <span class="variable">matplotlib.pyplot</span> <span class="keyword">as</span> <span class="variable">plt</span>
                            <br><span class="keyword">import</span> <span class="variable">numpy</span> <span class="keyword">as</span> <span class="variable">np</span>
                            <br><br>
                        
                            <span class="variable">temperature</span> = <span class="variable">np</span>.<span class="function">array</span>(<span class="function">range</span>(<span class="value">60</span>, <span class="value">100</span>, <span class="value">2</span>))
                            <br><span class="variable">temperature</span> = <span class="variable">temperature</span>.<span class="function">reshape</span>(-<span class="value">1</span>, <span class="value">1</span>)
                            <br><span class="variable">sales</span> = [<span class="value">65</span>, <span class="value">58</span>, <span class="value">46</span>, <span class="value">45</span>, <span class="value">44</span>, <span class="value">42</span>, <span class="value">40</span>, <span class="value">40</span>, <span class="value">36</span>, <span class="value">38</span>, <span class="value">38</span>, <span class="value">28</span>, <span class="value">30</span>, <span class="value">22</span>, <span class="value">27</span>, <span class="value">25</span>, <span class="value">25</span>, <span class="value">20</span>, <span class="value">15</span>, <span class="value">5</span>]
                            <br><br>
                        
                            <span class="variable">line_fitter</span> = <span class="variable">LinearRegression</span>()
                            <br><br>
                        
                            <span class="variable">line_fitter</span>.<span class="function">fit</span>(<span class="variable">temperature</span>, <span class="variable">sales</span>)
                            <br><br>
                        
                            <span class="variable">sales_predict</span> = <span class="variable">line_fitter</span>.<span class="function">predict</span>(<span class="variable">temperature</span>)
                            <br><br>
                        
                            <span class="variable">plt</span>.<span class="function">plot</span>(<span class="variable">temperature</span>, <span class="variable">sales</span>, <span class="value">'o'</span>)
                            <br><span class="variable">plt</span>.<span class="function">plot</span>(<span class="variable">temperature</span>, <span class="variable">sales_predict</span>)
                            <br><span class="variable">plt</span>.<span class="function">show</span>()
                            </code>
                        </pre>

                        <br>
                        <p>* While studying this course, I had to create a project for one of my Master's classes, and I chose to create a Convolutional Neural Network:</p>
                        <br>
                        <p><b>Project</b>:</p>
                        <div class="project">
                            <img src="https://i.imgur.com/HNTzXgQ.png" id="project-logo">
                            <div class="project-content">
                                <a href="https://github.com/asandenis/Pneumatix-Pneumonia-Detection-CNN-Model" target="_blank"><p><b>Pneumatix</b>: A Pneumonia Detection Convolutional Neural Network</p></a>
                                <p>A Convolutional Neural Network that detects pneumonia from x-ray lung images, and a Flask application.<br>* While it is not a Linear Regression Model, this was my first Machine Learning Project.</p>
                            </div>
                        </div>

                        <br>

                        <p><b>Multiple Linear Regression</b>: takes simple Linear Regression to the next level by allowing multiple <i>independent variables</i> to influence the <i>dependent variable</i>, not only one.</p>
                        <p>It's formula is the following:</p>
                        <p id="math">y=b+m₁x₁+m₂x₂+...+mₙxₙ</p>

                        <br>

                        <p><b>Training and Test sets</b>: those are partitions of the datasets used specifically for training the model, respectively to test the model's performance to provide an unbiased evaluation of it.</p>
                        <p>A general rule of thumb when splitting the initial dataset would be that the training set should have around 80% of the initial data, while the test set should have around 20%.</p>

                        <br>
                        
                        <p>If we divide the initial dataset in two variable: x and y, where y is the dependent variable, and x is a numpy array of the independent variables, we can automatically split this data into a training and a test set using <i>train_test_split</i> as follows:</p>
                        <pre class="code-block">
                            <code>
                                <span class="keyword">from</span> <span class="variable">sklearn</span>.<span class="function">model_selection</span> <span class="keyword">import</span> <span class="variable">train_test_split</span>
                                <br><br>
                                <span class="variable">x_train</span>, <span class="variable">x_test</span>, <span class="variable">y_train</span>, <span class="variable">y_test</span> = <span class="variable">train_test_split</span>(<span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">train_size</span>=<span class="variable">0.8</span>, <span class="variable">test_size</span>=<span class="variable">0.2</span>, <span class="variable">random_state</span>=<span class="variable">6</span>)
                            </code>
                        </pre>
                        <p>The <i>random_state</i> is used in order to create a seed, so that if you need to always have the same split, you can get it by having the same seed set.</p>

                        <br>

                        <p>Building and training a Multiple Linear Regression Model using scikit-learn:</p>
                        <pre class="code-block">
                            <code>
                                <span class="keyword">from</span> <span class="variable">sklearn</span>.<span class="function">linear_model</span> <span class="keyword">import</span> <span class="variable">LinearRegression</span>
                                <br><br>
                                <span class="variable">mlr</span> = <span class="variable">LinearRegression</span>()
                                <br><br>
                                <span class="variable">mlr</span>.<span class="function">fit</span>(<span class="variable">x_train</span>, <span class="variable">y_train</span>)
                                <br><br>
                                <span class="variable">y_predicted</span> = <span class="variable">mlr</span>.<span class="function">predict</span>(<span class="variable">x_test</span>) <span class="comment"># Or any data from which you want to predict the dependent variable.</span>
                            </code>
                        </pre>

                        <br>

                        <p>Using Matplotlib to create a 2D scatterplot:</p>
                        <pre class="code-block">
                            <code>
                                <span class="keyword">import</span> <span class="variable">matplotlib</span>.<span class="function">pyplot</span> <span class="keyword">as</span> <span class="variable">plt</span>
                                <br><br>
                                <span class="variable">plt</span>.<span class="function">scatter</span>(<span class="variable">x</span>, <span class="variable">y</span>, <span class="variable">alpha</span>=<span class="variable">0.5</span>) <span class="comment"># Alpha is used to determine the opacity of the points of the graph from 0 (0%) to 1 (100%).</span>
                                <br><br>
                                <span class="variable">plt</span>.<span class="function">xlabel</span>(<span class="value">"the x-axis label"</span>)
                                <br>
                                <span class="variable">plt</span>.<span class="function">ylabel</span>(<span class="value">"the y-axis label"</span>)
                                <br><br>
                                <span class="variable">plt</span>.<span class="function">title</span>(<span class="value">"plot title"</span>)
                                <br><br>
                                <span class="variable">plt</span>.<span class="function">show</span>()
                            </code>
                        </pre>

                        <p>Reminder, the mathematical formula is:</p>
                        <p id="math">y=b+m₁x₁+m₂x₂+...+mₙxₙ</p>
                        <p>where b is the intercept, and m₁, m₂, ..., mₙ are the coefficients.</p>
                        
                        <br>

                        <p>sklearn's model offers us two relevant pieces of data, the coefficients and the intercept:</p>
                        <pre class="code-block">
                            <code>
                                <span class="variable">mlr</span>.<span class="function">coef_</span>
                                <br>
                                <span class="variable">mlr</span>.<span class="function">intercept_</span>
                            </code>
                        </pre>

                        <p>The larger the module of the coefficient is, the more it influences the dependent variable, and it's sign (+ or -) decide if the influence is a positive or a negative one.</p>

                        <br>
                        
                        <p>To see the way a coefficent influences the dependent variable, we can plot them together. If the trend is upward, there is a positive linear relationship, and when there is a downward trend, there is a negative linear relationship. If there is no trend, there is no linear relationship or influence between the two variables.</p>

                        <br>

                        <p>To evaluate a Multiple Linear Regression model's accuracy we can use one of the following tests:</p>
                        <ol>
                            <li>
                                <p><b>Residual Analysis</b>: calculating the difference between the actual y value, and the predicted y' value, using the following formula:</p>
                                <p id="math">e=y-y'</p>
                                <p>The lower the <i>residual e</i> is, the better the model performs.</p>
                            </li>
                            <li>
                                <p><b>The coefficient R²</b> is defined as:</p>
                                <p id="math">1-
                                    <math>
                                        <mfrac>
                                          <mn>u</mn>
                                          <mi>v</mi>
                                        </mfrac>
                                    </math>
                                </p>
                                <p>where u is the residual sum of squares:</p>
                                <pre class="code-block">
                                    <code>
                                        ((<span class="variable">y</span> - <span class="variable">y_predict</span>) ** <span class="variable">2</span>).<span class="function">sum</span>()
                                    </code>
                                </pre>
                                <p>and v is the total sum of squares (or TSS):</p>
                                <pre class="code-block">
                                    <code>
                                        ((<span class="variable">y</span> - <span class="variable">y</span>.<span class="function">mean</span>()) ** <span class="variable">2</span>).<span class="function">sum</span>()
                                    </code>
                                </pre>
                                <p>R² can take both positive and negative values, however it cannot excced 1. It basically tells us to what extent (or percentage) the independent variables we chose explain the dependent variable. The closer R² is to 1, the better. Usually a R² of 0.7 or upper is considered good.</p>

                                <br>

                                <p>scikit-learn gives us the <i>score()</i> function that calculates R² automatically:</p>
                                <pre class="code-block">
                                    <code>
                                        <span class="variable">mlr</span>.<span class="function">score</span>(<span class="variable">x_train</span>, <span class="variable">y_train</span>)
                                        <br>
                                        <span class="variable">mlr</span>.<span class="function">score</span>(<span class="variable">x_test</span>, <span class="variable">y_test</span>)
                                    </code>
                                </pre>
                            </li>
                        </ol>

                        <p><b>Project</b>:</p>
                        <div class="project">
                            <img src="https://i.imgur.com/vKACaSs.png" id="project-logo">
                            <div class="project-content">
                                <a href="https://github.com/asandenis/codecademy-projects/tree/main/Machine%20Learning%20%26%20AI%20Engineer%20Course/TennisAce" target="_blank"><p><b>TennisAce</b>: A couple of Linear Regression and Multiple Linear Regression models that predict the ammount of winnings a tennis player will have based on different independent variables.</p></a>
                            </div>
                        </div>

                        <br>

                        <p><b>Logistic Regression</b>: refers to a supervised Machine Learning algorithm that predicts the probability, ranging from 0 to 1, of a datapoint belonging to a specific category, or class. These probabilities can then be used to assign, or classify, observations to the more probable group.</p>

                        <br>

                        <p>Example usages include predicting if an email is spam or not, if a tumor is malignant or not, or if a visitor would turn into a customer or not. It is primarily used for classification.</p>

                        <br>

                        <p>The mathematical formula behind logistic regression starts from the linear regression function, and applies a <i>logit link function</i> to the left-hand side, as such:</p>

                        <p id="math">ln(
                            <math>
                                <mfrac>
                                  <mn>7</mn>
                                  <mi>(1-y)</mi>
                                </mfrac>
                            </math>
                        )=b₀ + b₁x₁ + b₂x₂ + ... + bₙxₙ</p>
                        
                        <br>

                        <p>The right-hand side:</p>
                        <p id="math">ln(p/(1-p))</p>
                        <p>where p is the probability, is called a <i>log-odd</i>, because it is the natural logarithm of the probability.</p>

                        <p><b>Example:</b></p>
                        <p id="math">p=0.7 => 
                            <math>
                                <mfrac>
                                  <mn>p</mn>
                                  <mi>(1-p)</mi>
                                </mfrac>
                            </math> = 
                            <math>
                                <mfrac>
                                  <mn>0.7</mn>
                                  <mi>0.3</mi>
                                </mfrac>
                            </math>≈ 2.33</p>
                        <p>This means that the event A (with probability p) is 2.33 times more likely to happen than not happen.</p>

                        <br>

                        <p>The natural logarithm in the log-odd transformation helps in converting this ratio (always positive) into a real number that can vary from negative to positive infinity. This enables logistic regression to interpret and handle binary classification.</p>

                        <br>

                        <p>As we want to find the probability itself, we have to adjust the function to calculate <i>p</i>. In order to do this, we need to apply the inverse of the logit function, which is the <i>Sigmoid function</i>. When plotted, this function will have an S-shaped curve between 0 and 1, representing probabilities.</p>

                        <p><b>The coefficients of the model</b> can be interpreted as follows:</p>
                        <ul>
                            <li><p><b>Large positive coefficient</b>: a one-unit increase in this feature is associated with a large increase in the log odds (and therefore probability) of a data point belonging to the positive class (the outcome group labeled as 1).</p></li>
                            <li><p><b>Large negative coefficient</b>: a one-unit increase in this feature is associated with a large decrease in the log odds/probability of belonging to the positive class.</p></li>
                            <li><p><b>Coefficient of 0</b>: the feature is not associated with the outcome.</p></li>
                        </ul>

                        <p>Creating and fitting a Logistic Regression model using scikit-learn:</p>
                        <pre class="code-block">
                            <code>
                                <span class="keyword">from</span> <span class="variable">sklearn.linear_model</span> <span class="keyword">import</span> <span class="variable">LogisticRegression</span>
                                <br><span class="variable">model</span> = <span class="variable">LogisticRegression</span>()
                                <br><br>
                                <span class="variable">model</span>.<span class="function">fit</span>(<span class="variable">features</span>, <span class="variable">labels</span>)
                            </code>
                        </pre>

                        <p>Getting the coefficient(s) and the intercept:</p>
                        <pre class="code-block">
                            <code>
                                <span class="variable">model</span>.<span class="variable">coef_</span>  # This is a vector of the coefficients of each feature.
                                <br><span class="variable">model</span>.<span class="variable">intercept_</span>
                            </code>
                        </pre>

                        <p>Prediction can be done using the <i>.predict()</i> function, which returns the predicted category (1 or 0), or the <i>.predict_proba()</i> function (which gives you the probability itself).</p>

                        <br>

                        <p>By default, scikit-learn uses a threshold of 0.5. If a predicted probability is greater than or equal to 0.5, the entity is classified as '1' (positive class); otherwise, it is classified as '0' (negative class).</p>

                        <pre class="code-block">
                            <code>
                                <span class="variable">model</span>.<span class="function">predict</span>(<span class="variable">features</span>)
                                <br><span class="variable">model</span>.<span class="function">predict_proba</span>(<span class="variable">features</span>)
                            </code>
                        </pre>

                        <p>To adjust the threshold, you can specify a custom threshold as follows:</p>

                        <pre class="code-block">
                            <code>
                                <span class="variable">threshold</span> = <span class="value">0.9</span> <span class="comment"># Setting a 90% threshold.</span>
                                <br><span class="variable">model</span>.<span class="function">predict_proba</span>(<span class="variable">features</span>)[:, <span class="value">1</span>] >= <span class="variable">threshold</span>
                            </code>
                        </pre>

                        <p>In order to evaluate the model, we can use the following methods:</p>
                        <ul>
                            <li><b>Confusion matrix</b>: which tells us how many true-negatives, false-negatives, true-positives, and false-positives the model returns, based on the test dataset (the y_test, and the predictions returned by the model).</li>
                            <pre class="code-block">
                                <code>
                                    <span class="keyword">from</span> <span class="variable">sklearn.metrics</span> <span class="keyword">import</span> <span class="variable">confusion_matrix</span>
                                    <br><span class="variable">confusion_matrix</span>(<span class="variable">y_test</span>, <span class="variable">y_pred</span>)
                                </code>
                            </pre>
                            <p>The main diagonal are the true-negatives and true-positives, therefore we want the numbers of the main diagonal to be as high as possible, while the ones from the secondary diagonal should be as low as possible for the model to perform well.</p>
                            
                            <li><b>Confusion matrix statistical measurements</b>:</li>
                            <ol>
                                <li>
                                    <p><b>Accuracy</b>:</p>
                                    <p id="math">
                                        <math>
                                            <mfrac>
                                              <mn>(TP + TN)</mn>
                                              <mi>(TP + FP + TN + FN)</mi>
                                            </mfrac>
                                        </math>
                                    </p>
                                </li>
                                <li>
                                    <p><b>Precision</b>:</p>
                                    <p id="math">
                                        <math>
                                            <mfrac>
                                              <mn>TP</mn>
                                              <mi>(TP + FP)</mi>
                                            </mfrac>
                                        </math>
                                    </p>
                                </li>
                                <li>
                                    <p><b>Recall</b>:</p>
                                    <p id="math">
                                        <math>
                                            <mfrac>
                                              <mn>TP</mn>
                                              <mi>(TP + FN)</mi>
                                            </mfrac>
                                        </math>
                                    </p>
                                </li>
                                <li><p><b>F1 score</b>: weighted average of precision and recall.</p></li>
                            </ol>
                            <p>where TP is true positive, TN is true negative, FP is false positive, and FN is false negative.</p>

                            <br>

                            <p>To use them inside of scikit-learn we can write the following code:</p>

                            <pre class="code-block">
                                <code>
                                    <span class="keyword">from</span> <span class="variable">sklearn.metrics</span> <span class="keyword">import</span> <span class="variable">accuracy_score</span>
                                    <br><span class="variable">accuracy_score</span>(<span class="variable">y_test</span>, <span class="variable">y_pred</span>)
                                    <br><br>
                                    <span class="keyword">from</span> <span class="variable">sklearn.metrics</span> <span class="keyword">import</span> <span class="variable">precision_score</span>
                                    <br><span class="variable">precision_score</span>(<span class="variable">y_test</span>, <span class="variable">y_pred</span>)
                                    <br><br>
                                    <span class="keyword">from</span> <span class="variable">sklearn.metrics</span> <span class="keyword">import</span> <span class="variable">recall_score</span>
                                    <br><span class="variable">recall_score</span>(<span class="variable">y_test</span>, <span class="variable">y_pred</span>)
                                    <br><br>
                                    <span class="keyword">from</span> <span class="variable">sklearn.metrics</span> <span class="keyword">import</span> <span class="variable">f1_score</span>
                                    <br><span class="variable">f1_score</span>(<span class="variable">y_test</span>, <span class="variable">y_pred</span>)
                                </code>
                            </pre>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="tab-content" data-content="data-scientist">
                <h1>Data Scientist: Machine Learning Specialist</h1>
                <p>This lesson has not been yet started.</p>
            </div>
        </div>
    </body>
</html>